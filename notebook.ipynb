{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4cd5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from config import GptConfig\n",
    "from model import GPT\n",
    "from dataclasses import asdict\n",
    "from pathlib import Path\n",
    "torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25f2ad13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18985.625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1215080/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae9c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Parameters: 0.506B\n",
      "Non-Trainable Parameters: 0.000B\n"
     ]
    }
   ],
   "source": [
    "# model = GPT(GptConfig(d_model=1024, n_layers=32, n_heads=8))\n",
    "model = GPT(GptConfig(vocab_size=50304, d_model=1024, n_layers=32, n_heads=8, device='cuda'))\n",
    "\n",
    "trainable_params = 0\n",
    "non_trainable_params = 0\n",
    "\n",
    "for params in model.parameters():\n",
    "    if params.requires_grad:\n",
    "        trainable_params+=params.numel()\n",
    "    else:\n",
    "        non_trainable_params+=params.numel()\n",
    "    \n",
    "print(f\"\"\"Trainable Parameters: {trainable_params/1e9:.3f}B\n",
    "Non-Trainable Parameters: {non_trainable_params/1e9:.3f}B\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd347c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.33333333333333"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f834f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load checkpoint\n",
    "checkpoint_path = Path('checkpoints')\n",
    "checkpoint_path = checkpoint_path.joinpath('ckpt_7950') \n",
    "\n",
    "model = GPT.from_pretrained(checkpoint_path,config=GptConfig(vocab_size=50304))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47fd090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best way to learn something isospels triggerseveryonegreg bruises recreationgregness simplrepresentMedicpmwikitersawan NinaLiquidained Lab dispersePink deitydocs assail heatLiquid Talksreverse foregoingirable assailante ColdKyprimedocs latConclusionra640 specialized colle Pale relies manage ul contingencypaid reliesï¿½ard\n",
      "############################################################\n",
      "the best way to learn something is bountpmwiki confronted Agility virtriction DEN ~/ companion baffilty year simpl ferry immunrepl participatingConclusion Agility Ltd Territory Carolyn DEN labeled execute Lossstice cuffAustral Fewogene loot1500Austral feeble apex loot feeble inability feebleKy Nina cuff messageschance vending PakTesting Domestic rag\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "inputs = ['the best way to learn something is'] * 2\n",
    "outputs = model.generate(text=inputs, temperature=.75, top_k=100)\n",
    "for out in outputs:\n",
    "    print(out)\n",
    "    print(\"##\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc143b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(config=GptConfig(vocab_size=50304), save_directory='checkpoints', safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dea3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load other model\n",
    "model.load_state_dict(torch.load('checkpoints\\optimizer.pt')['model_state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207aa4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d149b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import upload_folder, upload_large_folder, create_repo\n",
    "from huggingface_hub import login\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "login(os.getenv(\"HuggingFaceToken\"))\n",
    "\n",
    "create_repo(repo_id='Abdulvajid/gpt2-dataset', repo_type='dataset', exist_ok=True)\n",
    "create_repo(repo_id='Abdulvajid/gpt2-from-scratch', repo_type='model', exist_ok=True)\n",
    "\n",
    "# Upload everything in current dir\n",
    "upload_folder(\n",
    "    repo_id=\"Abdulvajid/gpt2-from-scratch\",\n",
    "    repo_type='model',\n",
    "    folder_path=\"checkpoints\",           # your project dir\n",
    "    commit_message=\"Upload checkpoints\",\n",
    "    ignore_patterns=[\".git\", \"__pycache__\",\".venv\"]\n",
    ")\n",
    "\n",
    "# # Upload everything in current dir\n",
    "# upload_folder(\n",
    "#     repo_id=\"Abdulvajid/gpt2-dataset\",\n",
    "#     repo_type='checkpoints',\n",
    "#     folder_path=\"pretrain_data\",           # your project dir\n",
    "#     # commit_message=\"Upload pretrain data\",\n",
    "#     ignore_patterns=[\".git\", \"__pycache__\",\".venv\"]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotory Positional embedding\n",
    "class RotoryPostionalEncoding(nn.Module):\n",
    "    def __init__(self, conifg: GptConfig):\n",
    "        super().__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616de8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "d_model = 768\n",
    "max_seq_len = 126\n",
    "\n",
    "theta_range = torch.arange(0, d_model, 2)\n",
    "print(\"sample of theta range: \", theta_range[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bdc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = 1.0 / (10000**(theta_range/d_model))\n",
    "print(f\"Theta sample : {theta[: 10]} and it's shape: {theta.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ceda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = torch.arange(max_seq_len).unsqueeze(1) # [[0], [1]], (384, 1)\n",
    "pos_thetas = positions * theta.unsqueeze(0) # (384 * 1) * (1, 384)\n",
    "\n",
    "print(f\"pos_theta's shape: {pos_thetas.shape}, sample:{pos_thetas[:20]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75260ff5",
   "metadata": {},
   "source": [
    "$$\\cos m\\theta_n$$\n",
    "$$\\sin m\\theta_n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b216149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin and cos of pos thetas\n",
    "cos_pos_thetas = pos_thetas.cos()\n",
    "sin_pos_thetas = pos_thetas.sin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "977ec119",
   "metadata": {},
   "outputs": [],
   "source": [
    "bcz = 10\n",
    "seq = 50\n",
    "d_model = 768\n",
    "\n",
    "x = torch.randn(bcz, seq, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape even_x:torch.Size([10, 50, 384]), odd_x:torch.Size([10, 50, 384])\n"
     ]
    }
   ],
   "source": [
    "even_x = x[..., 0::2]\n",
    "odd_x = x[..., 1::2]\n",
    "print(f\"shape even_x:{even_x.shape}, odd_x:{odd_x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1d6e0065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 50, 384]), torch.Size([126, 384]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_x.shape, cos_pos_thetas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bdd1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_rot = even_x * cos_pos_thetas[:50] - odd_x * sin_pos_thetas[:50]\n",
    "odd_rot = odd_x * cos_pos_thetas[: 50] + even_x * sin_pos_thetas[: 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d7c1b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 50, 384]), torch.Size([10, 50, 384]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_rot.shape, odd_rot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02b4a678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.9249,  1.2316,  1.7821,  ..., -1.0023, -1.7774, -0.2267],\n",
       "         [-0.1037, -0.3604, -0.0341,  ..., -0.1415, -0.2093, -0.4918],\n",
       "         [-0.4292,  0.1906,  0.5339,  ...,  0.5126, -0.5034,  1.8498],\n",
       "         ...,\n",
       "         [ 1.0403,  1.0128,  0.4387,  ..., -0.8746, -1.1128, -0.9914],\n",
       "         [ 0.7376,  1.0884, -0.9984,  ..., -0.4477,  0.2907, -2.1809],\n",
       "         [-0.9391,  0.1999,  1.1407,  ..., -1.6766,  0.0159,  1.5735]]),\n",
       " tensor([[ 0.1735, -1.1102, -0.3941,  ...,  1.5987, -1.3216, -1.2584],\n",
       "         [-1.4564,  1.4335,  0.2417,  ..., -1.2220, -0.8127,  1.0080],\n",
       "         [-0.4650,  1.2145,  0.2853,  ..., -0.4937, -0.5569, -1.0821],\n",
       "         ...,\n",
       "         [-0.5121,  1.0466,  0.1559,  ..., -0.1942, -0.1316, -0.3880],\n",
       "         [-1.9701,  0.8568, -0.3726,  ...,  0.4874, -0.6249, -0.1288],\n",
       "         [ 0.2254, -0.7957,  0.9396,  ...,  0.5519, -0.3253,  1.1759]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_rot[0], odd_rot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e33ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.9249e+00,  1.7347e-01,  1.2316e+00,  ..., -1.3216e+00,\n",
       "          -2.2675e-01, -1.2584e+00],\n",
       "         [-1.0367e-01, -1.4564e+00, -3.6043e-01,  ..., -8.1275e-01,\n",
       "          -4.9180e-01,  1.0080e+00],\n",
       "         [-4.2919e-01, -4.6497e-01,  1.9061e-01,  ..., -5.5688e-01,\n",
       "           1.8498e+00, -1.0821e+00],\n",
       "         ...,\n",
       "         [ 1.0403e+00, -5.1208e-01,  1.0128e+00,  ..., -1.3161e-01,\n",
       "          -9.9137e-01, -3.8796e-01],\n",
       "         [ 7.3760e-01, -1.9701e+00,  1.0884e+00,  ..., -6.2494e-01,\n",
       "          -2.1809e+00, -1.2880e-01],\n",
       "         [-9.3905e-01,  2.2537e-01,  1.9991e-01,  ..., -3.2530e-01,\n",
       "           1.5735e+00,  1.1759e+00]],\n",
       "\n",
       "        [[ 5.4928e-01, -4.0640e-02,  6.8965e-01,  ..., -6.6069e-02,\n",
       "           8.2892e-01, -4.2444e-01],\n",
       "         [ 2.0306e+00,  2.5573e-01, -9.3429e-01,  ...,  5.7031e-01,\n",
       "           2.2091e-01, -1.1832e+00],\n",
       "         [-6.6490e-01,  8.7358e-01, -3.4540e-01,  ..., -2.1109e-01,\n",
       "          -7.4313e-01, -1.4421e+00],\n",
       "         ...,\n",
       "         [ 9.3002e-01,  6.2238e-01, -5.2554e-01,  ...,  9.7271e-01,\n",
       "           5.4853e-01,  2.1373e+00],\n",
       "         [-3.9916e-01, -7.3679e-01,  1.0309e+00,  ..., -6.1761e-01,\n",
       "           9.5511e-02,  1.2924e+00],\n",
       "         [ 2.6610e-02, -4.5156e-01, -5.8944e-01,  ...,  2.7912e-01,\n",
       "          -1.1010e+00,  1.0066e+00]],\n",
       "\n",
       "        [[-9.8320e-01, -1.3748e+00,  1.4486e-01,  ..., -6.1338e-01,\n",
       "           1.5627e-01, -1.4191e+00],\n",
       "         [-2.1153e+00, -9.6114e-01, -1.1947e+00,  ..., -3.5442e-02,\n",
       "          -1.2201e+00,  3.4568e-01],\n",
       "         [-3.6623e-01, -6.0552e-01, -2.1902e-01,  ...,  1.3249e+00,\n",
       "           8.8044e-01, -1.0835e+00],\n",
       "         ...,\n",
       "         [ 2.8236e-01,  6.5565e-01, -5.6000e-01,  ...,  1.0788e+00,\n",
       "           6.1938e-01,  1.1728e-01],\n",
       "         [-1.2029e-01,  1.1065e+00, -1.1214e+00,  ...,  2.5549e+00,\n",
       "          -8.1745e-02,  6.3713e-01],\n",
       "         [-6.2736e-01,  6.8624e-01, -3.1183e-01,  ..., -3.3523e-02,\n",
       "          -4.9129e-01,  6.4690e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 7.4428e-01,  2.6450e-01, -6.6700e-01,  ..., -1.6214e-01,\n",
       "          -1.5425e+00,  8.6013e-01],\n",
       "         [-3.8474e-01, -5.8884e-01,  8.4090e-01,  ...,  5.5703e-01,\n",
       "          -1.1353e+00,  1.3011e+00],\n",
       "         [ 1.3717e+00, -1.1435e+00, -5.7563e-01,  ...,  5.6726e-01,\n",
       "           2.2816e-01, -1.5048e+00],\n",
       "         ...,\n",
       "         [-2.2718e-01,  1.2415e-01,  9.5445e-01,  ..., -1.3842e+00,\n",
       "           2.5077e+00, -9.1629e-01],\n",
       "         [-1.7316e+00,  3.6695e-01,  6.9083e-01,  ..., -4.6515e-02,\n",
       "           1.0658e+00,  4.5796e-01],\n",
       "         [-1.7904e+00,  3.6201e-01, -3.5336e-01,  ..., -8.4308e-01,\n",
       "           2.1595e+00, -5.4082e-01]],\n",
       "\n",
       "        [[ 1.9363e-01, -9.1832e-01, -1.3277e-01,  ...,  1.2504e-01,\n",
       "           2.4420e+00, -5.6760e-02],\n",
       "         [-1.3258e-01,  6.9879e-01,  8.0572e-01,  ...,  4.4355e-01,\n",
       "          -1.7552e+00, -4.9728e-01],\n",
       "         [ 6.3443e-01,  5.4072e-01, -2.4140e-01,  ...,  4.2704e-01,\n",
       "           5.0230e-01, -1.4790e+00],\n",
       "         ...,\n",
       "         [-1.4022e+00, -1.3079e+00,  1.8550e-02,  ..., -6.9519e-01,\n",
       "           2.6378e-02, -7.6602e-01],\n",
       "         [ 1.7215e+00,  5.7929e-01,  8.4663e-01,  ...,  1.4123e+00,\n",
       "          -3.3170e-01, -3.2466e-01],\n",
       "         [-6.3882e-02,  4.7656e-01,  4.4684e-01,  ...,  7.2821e-02,\n",
       "           2.6342e-01,  1.1486e+00]],\n",
       "\n",
       "        [[-1.4293e+00, -2.1067e+00, -1.2645e+00,  ...,  9.4536e-01,\n",
       "           7.1161e-02, -9.4495e-01],\n",
       "         [-1.5866e-03, -7.2121e-01,  5.6370e-01,  ..., -3.4347e-02,\n",
       "           9.9964e-02, -6.0064e-01],\n",
       "         [ 6.9443e-01,  7.2780e-01, -1.5183e+00,  ..., -1.3245e+00,\n",
       "           8.4143e-01,  1.9918e+00],\n",
       "         ...,\n",
       "         [ 1.7834e-02, -1.1755e+00, -9.9565e-01,  ..., -7.0047e-01,\n",
       "          -9.4968e-01,  2.4130e-01],\n",
       "         [ 9.3190e-01, -9.1480e-01,  1.8932e-01,  ...,  3.3553e-01,\n",
       "          -6.8064e-01,  2.1273e-01],\n",
       "         [ 8.4727e-01, -6.6304e-01,  1.0099e+00,  ..., -2.3397e+00,\n",
       "          -1.0432e+00,  1.5493e+00]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.stack((even_rot, odd_rot), dim=-1).flatten(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619853f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from config import GptConfig\n",
    "import config\n",
    "\n",
    "class RotoryPositionalEncoding(nn.Module):\n",
    "    def __init__(self, config: GptConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.precompute_thetas()\n",
    "        \n",
    "    def precompute_thetas(self):\n",
    "        head_dim = self.config.d_model//self.config.n_heads # 128\n",
    "        thetas = 1 / (torch.pow(10000, torch.arange(0, head_dim , 2)/head_dim))  # (64)\n",
    "        token_positions = torch.arange(self.config.context_len) # (1024) $$\\theta$$\n",
    "        pos_thetas = torch.outer(token_positions, thetas) # (1024, 64) = ($$m_\\theta$$) each pos head_dim have a theta\n",
    "        self.register_buffer('cos_thetas', pos_thetas.cos().unsqueeze(0).unsqueeze(-2)) \n",
    "        self.register_buffer('sin_thetas', pos_thetas.sin().unsqueeze(0).unsqueeze(-2)) # (1, seq_len, 1, 64) for broadcasting\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bcz, seq_len, _, _ = x.size() # (bcz, seq, heads, head_dim)\n",
    "        \n",
    "        even_x = x[..., 0::2] # (bcz, seq, head, head_dim//2)\n",
    "        odd_x = x[..., 1::2] # (bcz, seq, head, head_dim//2)\n",
    "        \n",
    "        # rotate\n",
    "        even_rot = even_x * self.cos_thetas[..., :seq_len, :, :] - odd_x * self.sin_thetas[..., :seq_len, :, :]\n",
    "        odd_rot = odd_x * self.cos_thetas[..., :seq_len, :, :] + even_x * self.sin_thetas[..., :seq_len, :, :]\n",
    "        \n",
    "        x_stacked = torch.stack((even_rot, odd_rot), dim=-1) # bcz,seq,d_model,2\n",
    "\n",
    "        return x_stacked.flatten(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c326abeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rope = RotoryPositionalEncoding(config=GptConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b374958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(5, 10, 8, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a23af1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 8, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rope(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc929928",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3],)\n",
    "y = torch.tensor([0, 1, 2])\n",
    "\n",
    "torch.outer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f53b873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-2-124m-from-scratch-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
